{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9xJk0t8R8BW75kOKls/DH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semin1012/InhaGameStudy/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XhyAvtABvXm9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets  # 이미지에 관련된 패키지\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7szYwxSgvguJ",
        "outputId": "056c7b57-d764-4e49-f129-4375377c3378"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 25 07:20:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "TILKAWYiwtAw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lr\n",
        "learning_rate = 0.001\n",
        "training_epoch = 15     # 반복 횟수\n",
        "batch_size = 100        # 몇만 개 한 번에 받아들이면 느리니까 자르기 위함"
      ],
      "metadata": {
        "id": "HPncMoYNxJGa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mnist Dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,    # 학습 데이터\n",
        "                          transform=transforms.ToTensor(),  # torch.FloatTensor <- Byte 형태\n",
        "                          download=True)\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "metadata": {
        "id": "98f7CvZpxVu4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)   # batch_size로 나누었을 때 남는 데이터를 어떻게 할지 (True=사용)"
      ],
      "metadata": {
        "id": "BS45nXW0yVjI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cmtk3iZ4wtq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear1 = torch.nn.linear(2, 10, bias=True)\n",
        "# sigmoid = torch.nn.Sigmoid()\n",
        "# torch.nn.Sequential(linear1, sigmoid)\n",
        "# 위처럼 쓰면 가독성/유지보수가 안 좋아서 class 쓴다.\n",
        "# torch.nn.Module 에서 상속받아 쓴다\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.keep_prob=0.5\n",
        "        # (28, 28, 1)(H 가로, W 세로, C 채널) -> Tensor(C, H, W) -> DataLoader, + batchsize\n",
        "        # (BS=batchsize, C, H, W) 순서에 주의해야 한다.\n",
        "        # (100, 28, 28, 1)*(ks=3, s=1, p=1) -> (100, 32, 28, 28)\n",
        "        self.layer1 = torch.nn.Sequential(     # Init에서 초기화를 꼭 해야 한다.\n",
        "            torch.nn.Conv2d(in_channels=1,\n",
        "                            out_channels=32,    # 4의 배수로 해 준다. 이유: 알고리즘이 빠르게 동작하기 위해서\n",
        "                            kernel_size=3,      # 여러 시험 결과 가장 효율적인 수\n",
        "                            stride=1,\n",
        "                            padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # maxpool (100, 32, 28, 28) -> (100, 32, 14, 14)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32,\n",
        "                            64,\n",
        "                            3,\n",
        "                            1,\n",
        "                            1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        # (100, 32, 14, 14) -> (100, 64, 7, 7)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(\n",
        "                64,\n",
        "                128,\n",
        "                1,\n",
        "                1\n",
        "            ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        )\n",
        "        # (100, 64, 7, 7) -> (100, 128, 7/2, 7/2)\n",
        "        # 7/2는 3으로 나타내거나 4로 나타내야 한다. 패딩을 1로 주면 입력이 9가 돼서 4가 됨\n",
        "        # (100, 64, 9, 9) -> (100, 128, 4, 4)\n",
        "        self.fc1 = torch.nn.Linear(4*4*128, 625, bias=True)\n",
        "        # Drop Out, 과적합을 방지하는 테크닉\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            self.fc1,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p= 1-self.keep_prob)   # p = 0.5\n",
        "        )\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)          # 크기: (100, 128, 4, 4), layer4와 차원이 같지 않다.\n",
        "        out = out.view(out.size(0), -1) # 차원 맞춰 주려고 넣는 코드\n",
        "        out = self.layer4(out)          # 크기; (100, 128*4*4)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "LL99mKFdyuDR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to 를 왜 쓰냐? - 메모리에 올리는 건 명시적으로 적어줘야 한다. 쿠다 메모리에 넣어준다는 뜻이다.\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "8oGmVYxgzbcy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "LMAwrq6U4iDo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(training_epoch): # 15\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost/total_batch\n",
        "\n",
        "    print('Epoch:', epoch+1, 'Cost:', avg_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJqntC7W7ETo",
        "outputId": "26f9cc08-34e6-45db-a624-0d1761a08cba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Cost: tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 2 Cost: tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 3 Cost: tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 4 Cost: tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 5 Cost: tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 6 Cost: tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 7 Cost: tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 8 Cost: tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 9 Cost: tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 10 Cost: tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 11 Cost: tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 12 Cost: tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 13 Cost: tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 14 Cost: tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch: 15 Cost: tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기 영향 안 받고 실행할 수 있다\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)  # (0.1, 0.2, 0.3, ... ) = 총 합이 1이 되는 확률 ?? 네?\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPBmQBW67buB",
        "outputId": "42932a90-9e50-4238-a6f9-0e159b034fde"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9857999682426453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJnbCAMq838h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}